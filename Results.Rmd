## 结果汇总

### 各种方法的简要说明和比较
之前其实已经分散写在了height-biomass.rmd里，这里汇总整理一下。  

#### 简单相关  

1. Spearman rho更类似于Pearson r，只不过是用于ranked data。而Kendall tau与Goodman-Kruskal Gamma更为类似，“tau is just a standardized form of Gamma”。  
2. Spearman rho对极值点更为敏感，而tau和Gamma对所有数据点基本上同等敏感。  
3. Spearman更适用于（要求？）两个变量是单调线性的关系，Tau和Gamma则更“general”一些，反映总体正/负相关的trend。  
4. 存在ties的问题会使得Spearman/Kendall的效果变差；GK方法是对分类变量使用的，转换数据时也会损失一些信息。  

这样来看，Kendall和Goodman-Kruskal方法可能更适合分析我们的数据。  

#### 回归分析
Theil-Sen回归的breakdown point为29%左右，Siegel则可以达到50%（也是breakdown point可能达到的最大值了）。  
两种方法都非常稳健，适于应对转录组数据极值多这个问题。  

#### 矩阵相关
这个方法从原理上感觉比较难说出一二三条所以然来……但是有之前Fan的文献做出的效果还不错，因此觉得还是有较高的参考价值。  

#### 随机森林
机器学习应该是这些方法中认为最合适的一个，因为完全是data-driven，不存在数据极值点太多不适用于经典的统计模型的问题。  
目前存在的问题可能就是，只根据一部分数据回归得到的模型没有那么准确，但相较而言认为已经是最好的方法了。  

****

### 针对数据特点如何有效利用信息
转录组的数据极值可以差出很大，这些值事实上既包含了表达量高低的“正确、有用”的信息（所以这些点不是“错误的”，肯定不能干脆踢掉），又包含了被测量误差放大的差异（就是噪音？）。我们所要追求的，是如何将数据中含有的有效信息尽可能完整而真实地反映出来，又排除干扰，这应当是统计的一个很重要的目标。  

1. 优先考虑随机森林方法。  
2. 矩阵相关，感觉通过数据相除，在一定程度上可以缩小variation。  
3. 选择的相关和回归分析方法都是其中能较好应对离群点的。  

转录组数据为什么会有这么多极值点？**待查**

***

### 合理汇总和取舍结果
![Results](https://github.com/SunnyHZB/biomass/blob/master/Candidates.jpg "筛选结果汇总")  
使用了7种统计方法，去重后共筛选出47个基因（91次），图中标红的为至少3种方法都筛选出的基因。  
6种方法：Gene 195.  
5种方法：Gene 34, 62, 65, 77, 171.  
4种方法：Gene 13, 146, 260.  
3种方法：Gene 88, 251.  
共计11个，可以认为是可能性较大的候选基因。  

***

### 如何更好地回答最初的科学问题
在生物学功能不明的大背景下。  
**待完善**

***

### 科学问题和解决问题流程的调整
**待完善**